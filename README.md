# General info

Local deployment
In your root folder, create a .env file with your Llama 3 configuration:

You can then run Docker Compose to build and start all components:

docker-compose up --build

Additional configs
By default, the input sources (MLOps knowledge documents) are stored in the documents folder:

